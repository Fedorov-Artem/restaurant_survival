# restaurant_survival
### Project scope
This project's goal is to check which restaurants stay in business and which close. To answer this question, I used two datasets: one from 2021 scraped by STEFANO LEONE and published on Kaggle, and another scraped by me in 2023 as a part of the project; it is available in the current repository and also on Kaggle. The code used to scrape the TripAdvisor website and then clean the data is in the scraping_cleaning directory of this repository. The analysis was made in two Jupyter notebooks on Kaggle. The first notebook joins the datasets and calculates a number of distance features that take time to calculate, the other notebook contains the analysis itself. Both notebooks are also available in this repository.

As part of the analysis, an ML model that tries to predict which restaurants are going to close has been trained, and then features that increase the model's performance were selected. The most important features were visualized, including several maps.

### Data scraping and cleaning
The TripAdvisor website was scraped with the Selenium package, the code is in the restaurant_by_id.py file. The script uses an input list of known restaurant IDs from the 2021 dataset and saves the raw data in a *.csv file. That raw data is later cleaned with the code in the data_cleaning.py file. To distinguish better between restaurants that have actually closed but were not reported as closed on TripAdvisor and the restaurants that were closed, an additional check was performed: restaurant site URLs obtained during scraping were checked to determine whether the site is online or not. A significant number of restaurants list their Facebook page as their website, and to better understand which restaurants continue working, some additional information, including the date of the last post and description, was also collected from Facebook. The scraping script is available in check_websites.py, and the final cleaning code is in data_clean_final.py.

There are several more scraping and cleaning files in the directory. Those files were used to make a list of all restaurants from the selected countries that are available on TripAdvisor now. I decided to leave that data out of the scope of the project but leave the files in the repository, as this code is functional.

The joined dataset was produced using a Jupyter notebook because I wanted to make the process of producing a joined dataset publicly visible on Kaggle. In the same notebook, several distance count features were calculated (like the total number of restaurants that match some criteria within a certain distance from the restaurant).

### Subset of restaurants with known status
Unfotunately, it turned out that while TripAdvisor makes many checks before marking a restaurnat as closed, not all the restaurants that have actually closed are reported on Tripadvisor. That was a huge problem for the project, so I had to create a subset of restaurants that I could be sure are open. The process of creating the dataset is described in detail in the EDA notebook. 

### Analysis itself
After the subset of restaurants with known status is finalized, a number of features that are expected to correlate with the target feature are visualized. Then about 80 features are generated, and an ML model is fitted using all the features available. Then features of very low importance are removed. The volume of data is relatively small, so it is possible to check the model's performance without each single feature and then to remove features that decrease the model's performance the most until only important and useful features remain. In this project, a few features that increased the model's performance insignificantly were also removed. 

It turned out that it is impossible to make a good prediction about restaurants that are going to close; probably, the information that matters is not in the dataset. But it is possible to differentiate between restaurants that are more likely and less likely to close.
